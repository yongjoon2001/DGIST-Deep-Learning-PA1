# PA1: Neural Network & CNN Implementation

**DGIST CSE303 ë”¥ëŸ¬ë‹ê°œë¡  Programming Assignment 1**

[![GitHub](https://img.shields.io/badge/GitHub-Repository-blue?logo=github)](https://github.com/yongjoon2001/DGIST-Deep-Learning-PA1)

---

## ğŸ“‹ ê³¼ì œ ê°œìš”

MNIST ì†ê¸€ì”¨ ìˆ«ì ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ì—¬ **4ê°€ì§€ ë”¥ëŸ¬ë‹ ëª¨ë¸**ì„ êµ¬í˜„í•˜ê³  ë¹„êµ ë¶„ì„í•©ë‹ˆë‹¤:

1. **3-Layer Neural Network (Pure Python)** - `nn_pure_python.py`
2. **3-Layer Neural Network (PyTorch)** - `nn_framework.py`
3. **3-Layer CNN (Pure Python)** - `cnn_pure_python.py`
4. **3-Layer CNN (PyTorch)** - `cnn_framework.py`

### ğŸ¯ í•™ìŠµ ëª©í‘œ

- **ì´ë¡ ê³¼ ì‹¤ìŠµì˜ ì—°ê²°**: ê°•ì˜ìë£Œì˜ ìˆ˜ì‹ì„ ì§ì ‘ ì½”ë“œë¡œ êµ¬í˜„
- **í”„ë ˆì„ì›Œí¬ ë¹„êµ**: Pure Python vs PyTorch ì„±ëŠ¥ ë° êµ¬í˜„ ì°¨ì´ ì´í•´
- **ì•„í‚¤í…ì²˜ ì´í•´**: Fully Connected Networkì™€ CNNì˜ ì°¨ì´ ì²´ë“

---

## ğŸ—ï¸ ëª¨ë¸ ì•„í‚¤í…ì²˜

### 1ï¸âƒ£ 3-Layer Neural Network (Fully Connected)

```
Input (784)
  â†“
Linear Layer 1: 784 â†’ 128
  â†“
ReLU Activation
  â†“
Linear Layer 2: 128 â†’ 64
  â†“
ReLU Activation
  â†“
Linear Layer 3: 64 â†’ 10
  â†“
SoftMax (Output: 10 classes)
```

**ì„¤ê³„ ê·¼ê±°:**
- **784 input**: MNIST 28Ã—28 í”½ì…€ì„ flatten
- **128 â†’ 64 ê°ì†Œ**: ì ì§„ì  íŠ¹ì§• ì¶”ì¶œ ë° overfitting ë°©ì§€
- **ReLU**: Gradient vanishing ë¬¸ì œ í•´ê²°, ë¹ ë¥¸ í•™ìŠµ
- **10 output**: ìˆ«ì 0-9 ë¶„ë¥˜

**í•™ìŠµ ì„¤ì •:**
- Pure Python: Epochs 20, LR 0.1, SGD (manual)
- PyTorch: Epochs 20, LR 0.01, SGD (momentum=0.9)

---

### 2ï¸âƒ£ 3-Layer CNN (Convolutional Neural Network)

```
Input (28Ã—28Ã—1)
  â†“
Conv Layer 1: 1 â†’ 16 channels, 3Ã—3 kernel, padding=1
  â†“
ReLU + MaxPool (2Ã—2, stride=2) [28Ã—28 â†’ 14Ã—14]
  â†“
Conv Layer 2: 16 â†’ 32 channels, 3Ã—3 kernel, padding=1
  â†“
ReLU + MaxPool (2Ã—2, stride=2) [14Ã—14 â†’ 7Ã—7]
  â†“
Flatten: 32Ã—7Ã—7 = 1568
  â†“
Linear Layer: 1568 â†’ 10
  â†“
SoftMax (Output: 10 classes)
```

**ì„¤ê³„ ê·¼ê±°:**
- **ì±„ë„ ì¦ê°€ (1â†’16â†’32)**: ê³„ì¸µì  íŠ¹ì§• ì¶”ì¶œ (edge â†’ shape â†’ pattern)
- **3Ã—3 kernel + padding**: VGGNet ìŠ¤íƒ€ì¼, receptive field ìœ ì§€
- **MaxPooling**: ê³µê°„ ì°¨ì› ì¶•ì†Œ, translation invariance
- **Xavier ì´ˆê¸°í™”**: CNNì˜ ê¹Šì´ë¥¼ ê³ ë ¤í•œ weight ì´ˆê¸°í™”

**í•™ìŠµ ì„¤ì •:**
- Pure Python: Epochs 5, LR 0.01, Batch 16, SGD (manual)
- PyTorch: Epochs 10, LR 0.001, Batch 32, Adam

---

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
PA1/
â”œâ”€â”€ ğŸ“„ PA1_NN_CNN.pdf              # ê³¼ì œ ì„¤ëª…ì„œ
â”œâ”€â”€ ğŸ“„ README.md                   # í”„ë¡œì íŠ¸ ë¬¸ì„œ (ë³¸ íŒŒì¼)
â”‚
â”œâ”€â”€ ğŸ Python êµ¬í˜„ íŒŒì¼
â”‚   â”œâ”€â”€ nn_pure_python.py          # NN Pure Python êµ¬í˜„
â”‚   â”œâ”€â”€ nn_framework.py            # NN PyTorch êµ¬í˜„
â”‚   â”œâ”€â”€ cnn_pure_python.py         # CNN Pure Python êµ¬í˜„
â”‚   â”œâ”€â”€ cnn_framework.py           # CNN PyTorch êµ¬í˜„
â”‚   â””â”€â”€ run_all.py                 # ì „ì²´ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
â”‚
â”œâ”€â”€ ğŸ“‚ dataset/                    # MNIST ë°ì´í„°ì…‹
â”‚   â”œâ”€â”€ dataloader.py              # ì œê³µëœ ë°ì´í„°ë¡œë”
â”‚   â”œâ”€â”€ train-images-idx3-ubyte.gz
â”‚   â”œâ”€â”€ train-labels-idx1-ubyte.gz
â”‚   â”œâ”€â”€ t10k-images-idx3-ubyte.gz
â”‚   â””â”€â”€ t10k-labels-idx1-ubyte.gz
â”‚
â”œâ”€â”€ ğŸ“‚ checkpoints/                # í•™ìŠµëœ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ (ìë™ ìƒì„±)
â”‚   â”œâ”€â”€ nn_pure_python/
â”‚   â”‚   â”œâ”€â”€ model.pkl              # Pure Python ëª¨ë¸ íŒŒë¼ë¯¸í„°
â”‚   â”‚   â””â”€â”€ training_metrics.txt   # í•™ìŠµ ì§€í‘œ í…ìŠ¤íŠ¸ íŒŒì¼
â”‚   â”œâ”€â”€ cnn_pure_python/
â”‚   â”‚   â”œâ”€â”€ model.pkl
â”‚   â”‚   â””â”€â”€ training_metrics.txt
â”‚   â”œâ”€â”€ nn_framework/
â”‚   â”‚   â”œâ”€â”€ model.pth              # PyTorch ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸
â”‚   â”‚   â””â”€â”€ training_metrics.txt
â”‚   â””â”€â”€ cnn_framework/
â”‚       â”œâ”€â”€ model.pth
â”‚       â””â”€â”€ training_metrics.txt
â”‚
â””â”€â”€ ğŸ“‚ results/                    # ì‹œê°í™” ê²°ê³¼ë¬¼ (ìë™ ìƒì„±)
    â”œâ”€â”€ nn_pure_python/
    â”‚   â”œâ”€â”€ loss_graph.png         # Loss ë³€í™” ê·¸ë˜í”„
    â”‚   â”œâ”€â”€ confusion_matrix.png   # Confusion Matrix
    â”‚   â””â”€â”€ top3_images.png        # í´ë˜ìŠ¤ë³„ Top 3 ì´ë¯¸ì§€
    â”œâ”€â”€ nn_framework/
    â”œâ”€â”€ cnn_pure_python/
    â””â”€â”€ cnn_framework/
```

---

## ğŸš€ ì‹¤í–‰ ë°©ë²•

### ğŸ“¦ í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬

```bash
pip install numpy matplotlib seaborn torch
```

**ë¼ì´ë¸ŒëŸ¬ë¦¬ ìš©ë„:**
- `numpy`: ìˆ˜ì¹˜ ì—°ì‚° ë° Pure Python êµ¬í˜„
- `matplotlib`: ê·¸ë˜í”„ ì‹œê°í™”
- `seaborn`: Confusion matrix íˆíŠ¸ë§µ
- `torch`: PyTorch êµ¬í˜„ (nn_framework, cnn_framework)

---

### â–¶ï¸ ì‹¤í–‰ ì˜µì…˜

#### 1. ì „ì²´ ì‹¤í–‰ (ê¶Œì¥)

```bash
cd PA1
python run_all.py
```

**ì‹¤í–‰ ìˆœì„œ:**
1. 3-Layer Neural Network (Pure Python)
2. 3-Layer Neural Network (PyTorch)
3. 3-Layer CNN (Pure Python)
4. 3-Layer CNN (PyTorch)

ëª¨ë“  ê²°ê³¼ê°€ `results/` ë° `checkpoints/` í´ë”ì— ì €ì¥ë©ë‹ˆë‹¤.

---

#### 2. ê°œë³„ ì‹¤í–‰

```bash
cd PA1

# Neural Network (Pure Python)
python nn_pure_python.py

# Neural Network (PyTorch)
python nn_framework.py

# CNN (Pure Python)
python cnn_pure_python.py

# CNN (PyTorch)
python cnn_framework.py
```

---

## ğŸ“Š ê²°ê³¼ë¬¼ ìƒì„¸ ì„¤ëª…

### 1ï¸âƒ£ **Loss Graph** (`loss_graph.png`)

- **ë‚´ìš©**: Training Lossì™€ Test Lossì˜ ì—í¬í¬ë³„ ë³€í™”
- **ëª©ì **:
  - Overfitting ê°ì§€ (Train â†“, Test â†‘)
  - í•™ìŠµ ìˆ˜ë ´ í™•ì¸
  - ëª¨ë¸ ì„±ëŠ¥ íŠ¸ë Œë“œ ë¶„ì„

**ì˜ˆì‹œ:**
```
Epoch 1: Train Loss 2.3, Test Loss 2.1
Epoch 20: Train Loss 0.1, Test Loss 0.15
```

---

### 2ï¸âƒ£ **Confusion Matrix** (`confusion_matrix.png`)

- **í¬ê¸°**: 10Ã—10 (í´ë˜ìŠ¤ 0-9)
- **ê°’**: ì •ê·œí™”ëœ í™•ë¥  (0.00 ~ 1.00)
- **ëŒ€ê°ì„ **: ì •í™•íˆ ë¶„ë¥˜ëœ í™•ë¥  (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)
- **ë¹„ëŒ€ê°ì„ **: ì˜¤ë¶„ë¥˜ íŒ¨í„´ (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)

**ê°œì„  ì‚¬í•­:**
- âœ… ëª¨ë“  ì…€ì— ìˆ«ì í‘œì‹œ (ìˆ˜ë™ annotation)
- âœ… í…ìŠ¤íŠ¸ ìƒ‰ìƒ ìë™ ì¡°ì • (ê°€ë…ì„±)
- âœ… ê³ í•´ìƒë„ (DPI 300)

**í•´ì„ ì˜ˆì‹œ:**
```
ì‹¤ì œ 8 â†’ ì˜ˆì¸¡ 8: 0.95 (ì •í™•)
ì‹¤ì œ 8 â†’ ì˜ˆì¸¡ 3: 0.03 (ì˜¤ë¶„ë¥˜)
```

---

### 3ï¸âƒ£ **Top 3 Images** (`top3_images.png`)

- **ë ˆì´ì•„ì›ƒ**: 10Ã—3 ê·¸ë¦¬ë“œ (10ê°œ í´ë˜ìŠ¤, ê° 3ê°œ ì´ë¯¸ì§€)
- **ì„ ì • ê¸°ì¤€**: ëª¨ë¸ì´ ê°€ì¥ ë†’ì€ confidenceë¡œ ì˜ˆì¸¡í•œ ì´ë¯¸ì§€
- **í‘œì‹œ ì •ë³´**:
  - í´ë˜ìŠ¤ ë²ˆí˜¸
  - ìˆœìœ„ (1, 2, 3)
  - Confidence ê°’

**í™œìš©:**
- ëª¨ë¸ì´ "í™•ì‹ í•˜ëŠ”" ì´ë¯¸ì§€ íŒ¨í„´ ë¶„ì„
- í´ë˜ìŠ¤ë³„ í•™ìŠµ í’ˆì§ˆ í™•ì¸

---

### 4ï¸âƒ£ **Training Metrics** (`training_metrics.txt`)

**ìƒˆë¡œ ì¶”ê°€ëœ ê¸°ëŠ¥!** ğŸ“

í•™ìŠµ ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ì €ì¥í•˜ì—¬ ì‰½ê²Œ ë¹„êµ ê°€ëŠ¥:

```txt
============================================================
3-Layer Neural Network (PyTorch) - Training Metrics
============================================================

Model Architecture:
  Input Layer: 784 neurons
  Hidden Layer 1: 128 neurons (ReLU)
  Hidden Layer 2: 64 neurons (ReLU)
  Output Layer: 10 neurons (CrossEntropyLoss)

Training Configuration:
  Epochs: 20
  Learning Rate: 0.01
  Batch Size: 32
  Optimizer: SGD (momentum=0.9)
  Loss Function: CrossEntropyLoss
  Device: CPU

Final Results:
  Train Accuracy: 0.9876 (98.76%)
  Test Accuracy: 0.9654 (96.54%)
  Final Train Loss: 0.0423
  Final Test Loss: 0.1234

Loss History (per epoch):
------------------------------------------------------------
Epoch      Train Loss      Test Loss
------------------------------------------------------------
1          2.3012          2.1543
2          1.8765          1.7234
...
20         0.0423          0.1234
```

**í¬í•¨ ì •ë³´:**
- ëª¨ë¸ ì•„í‚¤í…ì²˜ ìƒì„¸
- í•™ìŠµ ì„¤ì • (í•˜ì´í¼íŒŒë¼ë¯¸í„°)
- ìµœì¢… ì •í™•ë„ ë° ì†ì‹¤
- ì „ì²´ ì—í¬í¬ Loss íˆìŠ¤í† ë¦¬

---

## ğŸ”¬ êµ¬í˜„ ì„¸ë¶€ì‚¬í•­

### Pure Python êµ¬í˜„

**íŠ¹ì§•:**
- **NumPyë§Œ ì‚¬ìš©**: í”„ë ˆì„ì›Œí¬ ì—†ì´ ìˆœìˆ˜ êµ¬í˜„
- **Forward Propagation**: ìˆ˜ë™ í–‰ë ¬ ì—°ì‚°
- **Backward Propagation**: Gradient ì§ì ‘ ê³„ì‚°
  ```python
  dW = np.dot(input.T, dout)
  db = np.sum(dout, axis=0, keepdims=True)
  ```
- **Weight Update**: ìˆ˜ë™ SGD
  ```python
  W -= learning_rate * dW
  b -= learning_rate * db
  ```

**CNN ì¶”ê°€ êµ¬í˜„:**
- Convolution ì—°ì‚° (4ì¤‘ for loop)
- MaxPooling (argmax ì¶”ì )
- Padding ì²˜ë¦¬

**ì¥ì :**
- ë‚´ë¶€ ë™ì‘ ì™„ì „ ì´í•´
- ë””ë²„ê¹… ìš©ì´
- êµìœ¡ì  ê°€ì¹˜

**ë‹¨ì :**
- ëŠë¦° ì†ë„ (íŠ¹íˆ CNN)
- GPU ë¯¸ì§€ì›

---

### PyTorch êµ¬í˜„

**íŠ¹ì§•:**
- **torch.nn ëª¨ë“ˆ**: `nn.Linear`, `nn.Conv2d`, `nn.MaxPool2d`
- **ìë™ ë¯¸ë¶„**: Autograd ì‹œìŠ¤í…œ
- **GPU ê°€ì†**: CUDA ì§€ì›
- **ìµœì í™”ëœ Optimizer**: Adam, SGD with Momentum

**ì½”ë“œ ì˜ˆì‹œ:**
```python
class ThreeLayerNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.layer1 = nn.Linear(784, 128)
        self.layer2 = nn.Linear(128, 64)
        self.layer3 = nn.Linear(64, 10)

    def forward(self, x):
        x = x.view(x.size(0), -1)
        x = F.relu(self.layer1(x))
        x = F.relu(self.layer2(x))
        x = self.layer3(x)
        return x
```

**ì¥ì :**
- ë¹ ë¥¸ í•™ìŠµ ì†ë„
- ì‚°ì—…ê³„ í‘œì¤€
- í™•ì¥ì„± ìš°ìˆ˜

---

## ğŸ“š ê°•ì˜ìë£Œ í™œìš©

### Slide03 (DL-Model)
- âœ… Linear layerì˜ forward/backward êµ¬í˜„
- âœ… Weight matrix ì—°ì‚°: `y = Wx + b`

### Slide05 (DL-Loss)
- âœ… Cross Entropy Loss êµ¬í˜„
- âœ… SoftMaxì™€ Lossì˜ ê²°í•©

### Slide06 (DL-Optimization)
- âœ… SGD, Momentum, Adam ì ìš©
- âœ… Learning rate scheduling ê°œë…

### Slide07 (Activation)
- âœ… ReLU êµ¬í˜„ ë° gradient ê³„ì‚°
- âœ… Vanishing gradient ë¬¸ì œ í•´ê²°

### Slide08 (ConvolutionalNeuralNet)
- âœ… Convolution, Pooling êµ¬í˜„
- âœ… Local connectivity, Parameter sharing
- âœ… LeNet-5 ë³€í˜• ì•„í‚¤í…ì²˜

---

## ğŸ¯ ì£¼ìš” íŠ¹ì§• ë° ê°œì„ ì‚¬í•­

### âœ¨ í•µì‹¬ ê¸°ëŠ¥

1. **ëª¨ë“ˆí™”ëœ ì„¤ê³„**
   - ê° ë ˆì´ì–´ë¥¼ ë…ë¦½ì ì¸ í´ë˜ìŠ¤ë¡œ êµ¬í˜„
   - ì¬ì‚¬ìš© ê°€ëŠ¥í•œ ì»´í¬ë„ŒíŠ¸

2. **ì‹¤ì‹œê°„ í•™ìŠµ ëª¨ë‹ˆí„°ë§**
   - ì—í¬í¬ë³„ Train/Test Loss ë° Accuracy ì¶œë ¥
   - ë°°ì¹˜ë³„ ì§„í–‰ ìƒí™© (CNN Pure Python)

3. **ì²´í¬í¬ì¸íŠ¸ ì‹œìŠ¤í…œ**
   - í•™ìŠµëœ ëª¨ë¸ ìë™ ì €ì¥
   - ì¬í•™ìŠµ ì—†ì´ ê²°ê³¼ ì¬í˜„ ê°€ëŠ¥

4. **ì¢…í•©ì  ì‹œê°í™”**
   - Loss graph, Confusion matrix, Top 3 images
   - ê³ í•´ìƒë„ (DPI 300) PNG ì €ì¥

5. **í…ìŠ¤íŠ¸ ê¸°ë°˜ ë¦¬í¬íŠ¸**
   - `training_metrics.txt` ìë™ ìƒì„±
   - í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¶€í„° ê²°ê³¼ê¹Œì§€ ëª¨ë“  ì •ë³´ í¬í•¨

---

### ğŸ”§ ìµœê·¼ ì—…ë°ì´íŠ¸

#### v1.3 (2025-10-07)
- âœ… Training metrics í…ìŠ¤íŠ¸ íŒŒì¼ ì €ì¥ ê¸°ëŠ¥ ì¶”ê°€
- âœ… Confusion matrix ëª¨ë“  ì…€ ìˆ«ì í‘œì‹œ ë³´ì¥
- âœ… í•™ìŠµ ì¤‘ ì •í™•ë„ ì‹¤ì‹œê°„ ì¶”ì 

#### v1.2 (2025-10-07)
- âœ… Confusion matrix ì‹œê°í™” ê°œì„  (ìˆ˜ë™ annotation)
- âœ… DPI 300ìœ¼ë¡œ ê³ í™”ì§ˆ ì´ë¯¸ì§€ ìƒì„±
- âœ… ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬ êµ¬ì¡°í™”

#### v1.1 (2025-10-07)
- âœ… nn_framework optimizer ë³€ê²½ (Adam â†’ SGD + Momentum)
- âœ… Learning rate ìµœì í™”
- âœ… ë°ì´í„° ê²€ì¦ ë¡œì§ ì¶”ê°€

---

## âœ… ê³¼ì œ ìš”êµ¬ì‚¬í•­ ì¶©ì¡±

| ìš”êµ¬ì‚¬í•­ | êµ¬í˜„ ì—¬ë¶€ | íŒŒì¼ |
|---------|----------|------|
| 3-Layer NN (Pure Python) | âœ… | `nn_pure_python.py` |
| 3-Layer NN (PyTorch) | âœ… | `nn_framework.py` |
| 3-Layer CNN (Pure Python) | âœ… | `cnn_pure_python.py` |
| 3-Layer CNN (PyTorch) | âœ… | `cnn_framework.py` |
| Training/Test Loss Graph | âœ… | `results/*/loss_graph.png` |
| Confusion Matrix | âœ… | `results/*/confusion_matrix.png` |
| Top 3 Images per Class | âœ… | `results/*/top3_images.png` |
| ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ | âœ… | `checkpoints/*/model.*` |
| í•™ìŠµ ì§€í‘œ ë¦¬í¬íŠ¸ | âœ… | `checkpoints/*/training_metrics.txt` |

---

## ğŸ“ˆ ì˜ˆìƒ ì„±ëŠ¥

| ëª¨ë¸ | Train Acc | Test Acc | í•™ìŠµ ì‹œê°„ (CPU) |
|------|-----------|----------|----------------|
| NN Pure Python | ~97% | ~95% | ~2ë¶„ |
| NN PyTorch | ~98% | ~96% | ~30ì´ˆ |
| CNN Pure Python | ~95% | ~92% | ~10ë¶„ |
| CNN PyTorch | ~99% | ~98% | ~1ë¶„ |

*ì„±ëŠ¥ì€ í•˜ë“œì›¨ì–´ ë° ì´ˆê¸° ê°€ì¤‘ì¹˜ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.*

---

## ğŸ› ë¬¸ì œ í•´ê²°

### 1. Import Error
```bash
ModuleNotFoundError: No module named 'torch'
```
**í•´ê²°:** `pip install torch`

### 2. ë©”ëª¨ë¦¬ ë¶€ì¡± (CNN Pure Python)
```bash
MemoryError: Unable to allocate array
```
**í•´ê²°:** Batch size ê°ì†Œ (16 â†’ 8)

### 3. Confusion Matrix ìˆ«ì ì•ˆ ë³´ì„
**í•´ê²°ë¨!** v1.2ë¶€í„° ìˆ˜ë™ annotationìœ¼ë¡œ ëª¨ë“  ì…€ í‘œì‹œ

---

## ğŸ“– ì°¸ê³  ìë£Œ

- **ê³¼ì œ ì„¤ëª…ì„œ**: `PA1_NN_CNN.pdf`
- **MNIST Dataset**: [http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/)
- **ê°•ì˜ìë£Œ**:
  - Slide03: DL-Model
  - Slide05: DL-Loss
  - Slide06: DL-Optimization
  - Slide07: DL-Activation
  - Slide08: ConvolutionalNeuralNet
- **ë…¼ë¬¸**:
  - LeNet-5 (1998)
  - AlexNet (2012)
  - VGGNet (2014)

---

## ğŸ‘¨â€ğŸ’» ê°œë°œ ì •ë³´

- **ê³¼ëª©**: CSE303 ë”¥ëŸ¬ë‹ê°œë¡ 
- **í•™êµ**: DGIST
- **GitHub**: [https://github.com/yongjoon2001/DGIST-Deep-Learning-PA1](https://github.com/yongjoon2001/DGIST-Deep-Learning-PA1)

---

## ğŸ“ ë¼ì´ì„¼ìŠ¤

This project is for educational purposes only.

---

**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸**: 2025-10-07
**ë²„ì „**: 1.3.0
